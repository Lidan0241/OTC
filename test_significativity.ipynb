{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import matplotlib as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 12, 11, 12, 12, 15, 17, 9, 13, 12, 16, 12, 12, 19, 16, 13, 11, 16, 11, 12, 17, 13, 11, 22, 21, 18, 13, 17, 11, 11, 11, 12, 21]\n",
      "[421, 336, 645, 293, 658, 667, 811, 320, 337, 531, 352, 595, 343, 440, 403, 479, 613, 753, 645, 526, 1447, 675, 469, 327, 873, 1202, 1252, 421, 594, 610, 478, 1566, 746]\n",
      "['World', 'Crime', 'World', 'Politics', 'U.S.', 'U.S.', 'World', 'Local News', 'Sports', 'Sports', 'Sports', 'Sports', 'Crime', 'Crime', 'Crime', 'Local', 'Local', 'Politics', 'World', 'World', 'World', 'HealthWatch', 'MoneyWatch', 'Technology', 'World', 'U.S.', 'World', 'World', 'MoneyWatch', 'MoneyWatch', 'MoneyWatch', 'MoneyWatch', 'MoneyWatch']\n",
      "['cbs', 'alnaji', 'aid', 'israel', 'usa', 'fire', 'temperature', 'boston', 'season', 'patriot', 'patriot', 'may', 'cbs', 'police', 'mexico', 'say', 'mosquito', 'say', 'aid', 'say', 'say', 'patient', 'nissan', 'audio', 'heat', 'storm', 'gaza', 'cbs', 'market', 'mcdonald', 'red', 'say', 'board']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataframe.csv')\n",
    "title_length = df['title_word_count'].tolist()\n",
    "content_length = df['content_word_count'].tolist()\n",
    "theme_list = df['theme'].tolist()\n",
    "frequent_word_list = df['frequent_word'].tolist()\n",
    "print(title_length)\n",
    "print(content_length)\n",
    "print(theme_list)\n",
    "print(frequent_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrélation de Pearson: 0.14842620588897987 P-value: 0.40974201978831193\n",
      "Corrélation de Spearman: 0.17542559848445458 P-value: 0.32882345690529835\n"
     ]
    }
   ],
   "source": [
    "# coefficient de corrélation de Pearson\n",
    "pearson_corr, pearson_pvalue = pearsonr(title_length, content_length)\n",
    "print(\"Corrélation de Pearson:\", pearson_corr, \"P-value:\", pearson_pvalue)\n",
    "\n",
    "# coefficient de corrélation de Spearman\n",
    "spearman_corr, spearman_pvalue = spearmanr(title_length, content_length)\n",
    "print(\"Corrélation de Spearman:\", spearman_corr, \"P-value:\", spearman_pvalue)\n",
    "\n",
    "# il n'y donc pas de corrélation entre la longueur de résumé et la longueur de contenu des articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'Word2Vec' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/lydia/Desktop/OTC-projet/test_significativity.ipynb Cell 5\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lydia/Desktop/OTC-projet/test_significativity.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m theme \u001b[39min\u001b[39;00m theme_list:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lydia/Desktop/OTC-projet/test_significativity.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m frequent_word_list:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lydia/Desktop/OTC-projet/test_significativity.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mif\u001b[39;00m theme \u001b[39min\u001b[39;49;00m model \u001b[39mand\u001b[39;00m word \u001b[39min\u001b[39;00m model:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lydia/Desktop/OTC-projet/test_significativity.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m             similarity \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39msimilarity(theme, word)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lydia/Desktop/OTC-projet/test_significativity.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msimilarité entre \u001b[39m\u001b[39m{\u001b[39;00mtheme\u001b[39m}\u001b[39;00m\u001b[39m et \u001b[39m\u001b[39m{\u001b[39;00mword\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00msimilarity\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'Word2Vec' is not iterable"
     ]
    }
   ],
   "source": [
    "# loading a pretrained model for word2vec\n",
    "#model = KeyedVectors.load_word2vec_format(\"./model_word2vec.bin\", binary=True, unicode_errors=\"ignore\")\n",
    "\n",
    "# conversion vecteurs + calcul similarité cosine\n",
    "for theme in theme_list:\n",
    "    for word in frequent_word_list:\n",
    "        if theme in model and word in model:\n",
    "            similarity = model.similarity(theme, word)\n",
    "            print(f\"similarité entre {theme} et {word}: {similarity:.4f}\")\n",
    "        else:\n",
    "            print(f\"One of the words, {theme} or {word}, is not in the vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corr, pearson_pvalue = pearsonr(title_length, content_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "extra-info",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
